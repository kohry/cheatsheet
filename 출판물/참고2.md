# 머신러닝

## kNN
장점 : 단순 효율, 비모수적 (추정필요없음)
단점 : 모델생성, lazy, 메모리, 명목 결측 추가처리


좋은 예 : 과일

유클리드 거리로 측정
k 3-10

필요하다면 스케일로 z점수 표준화하고, 명목형은 0,1 이렇게 인코딩을 한번 해줘도 된다. (더미코딩)

게으르다

normalize() 함수를 이용해서 스케일 확인

class 패키지에 knn(train, test, class, k) 가 존재함.

## naive bayes

모든 속성은 동등중요, 독립이라는 결함가정.
수치속성으로는 별로 좋지않음. (수치속성은 뭔가 절차를 거쳐줘야함)
빠르고 효과적, 결측노이즈 오케이, 예제잘수행

라플라스 추정기 (1) 더해주는게 필요 왜내면 다 뭉개지니까

수치속성으로는 구간화가 필요함. discretization or binning. cut point필요

text데이터는 tm_map을 통해 불용어 stop words 등을 처리.

단어 빈도수를 체크하는건 findFreqTerms

용어 빈도수를 목록저장하기 위해 Dictionary() 함수 사용

e1071 패키지에 나이브 베이즈 

## decision tree

설명을 잘해야하는 경우. 
근데 많은 수의 명목이나 수치데이터의 경우 특히. 

c5.0 

다수의 레벨을 가진 속성쪽으로 분류하는 경향, 쉽게 과적합, 과소적합.
큰트리는 직관과 멀고, 약간의 변경이 결정논리에 변화를 줌.

C50 라이브러리에 존재하고 있음.

adaptive boosting 이용하면, 계속해서 훈련을 할수 있다고 함.
비용 매트릭스를 통해, 고비용을 추가해서 조심해야하는 불류군에 대한 계산을 함.

## 선형회귀

수치데이터를 모델화하기 위한 일반적인 접근.
결측치와 작동을 잘 안함.
수치속성만 작동하고 범주형 데이터는 부가 처리 필요.

## 신경망
neuralnet 패키지

## 참조
awesomeR



